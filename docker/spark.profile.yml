version: '3.8'

services:

  spark-master:
    image: swh-spark-image
    entrypoint: ['spark_entrypoint.sh', 'master']
    environment:
      - SPARK_NO_DAEMONIZE=false
    healthcheck:
      test: ["CMD", "curl", "-f", "https://localhost:8080"]
      interval: 5s
      timeout: 3s
      retries: 3
    ports:
      - '4040:4040'
      - '7077:7077'
      - '9090:8080'
      - '51810:51810'
      - '51811:51811'
      - '51812:51812'
      - '51813:51813'
      - '51814:51814'
    volumes:
      - ./var/log/spark:/opt/spark/spark-events
      - ./code:/opt/spark/code
      - ./data:/opt/spark/data

  spark-history:
    depends_on:
      - spark-master
    image: swh-spark-image
    entrypoint: ['spark_entrypoint.sh', 'history']
    environment:
      - SPARK_NO_DAEMONIZE
    volumes:
      - ./docker/spark/spark-master-defaults.properties:/opt/spark/conf/spark-defaults.conf
      - ./var/log/spark:/opt/spark/spark-events
    ports:
     - '18080:18080'

  spark-worker:
    depends_on:
      - spark-master
    image: swh-spark-image
    entrypoint: ['spark_entrypoint.sh', 'worker']
    environment:
      - SPARK_NO_DAEMONIZE
    ports:
     - '9091:8081'
     - '51815:51815'
    volumes:
      - ./docker/spark/spark-worker-defaults.properties:/opt/spark/conf/spark-defaults.conf
      - ./var/log/spark:/opt/spark/spark-events
      - ./code:/opt/spark/code
      - ./data:/opt/spark/data


